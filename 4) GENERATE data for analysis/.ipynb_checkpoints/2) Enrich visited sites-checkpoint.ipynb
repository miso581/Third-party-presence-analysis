{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich visited sites with first-party categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    • input: (i) an .sqlite database file of a single harvest, and (ii) first-party categorisation\n",
    "    data (.csv)\n",
    "    • output: visitedSitesCat.csv - list of visited sites enriched with first-party categorisation data\n",
    "    • script steps:\n",
    "        1. Import libraries\n",
    "        2. Load the site_visits table from the database file as a DF\n",
    "        3. Load first-party categorisation data as a DF\n",
    "        4. Obtain a root-domain of all visited sites and append it as a new column of visited sites DF\n",
    "        5. Merge FP categorisation DF and visited sites DF based on respective first-party root domain column\n",
    "        6. Export the merged dataframe as visitedSitesCat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tld import get_tld, is_tld "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load visited sites categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path and name\n",
    "visited_cat_path = '/home/ubuntu/data/datasets_for_enrichment/provided/'\n",
    "visited_cat_file_name = 'SiteCategoriesUpdated.csv'\n",
    "\n",
    "# Load file as a dataframe\n",
    "df_visited_cat = pd.read_csv(visited_cat_path + visited_cat_file_name, header = 0, low_memory=False)\n",
    "df_visited_cat = df_visited_cat[['Country', 'Europe', 'PublicPrivate', 'SiteCategory', 'URLtype', 'TopLevelDomainLookUp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain all visited sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining a root domain of all sites in given dataframe's columns\n",
    "def get_root_url(df, column):\n",
    "\n",
    "    urls = df[column].astype(str).tolist()\n",
    "    root_url = []\n",
    "\n",
    "    # Loop through the list and obtain the root domain for each visited site\n",
    "    for site in urls:\n",
    "        root = get_tld(site, as_object=True, fail_silently=True)\n",
    "        if root != None:\n",
    "            url_domain = get_tld(site, as_object=True).fld\n",
    "            root_url.append(url_domain)\n",
    "        else:\n",
    "            root_url.append(site)\n",
    "\n",
    "    return(root_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site visits table loaded\n"
     ]
    }
   ],
   "source": [
    "# Create a database connection to the SQLite database specified by the db_file\n",
    "# Load a visited sites table\n",
    "\n",
    "conn = None\n",
    "try:\n",
    "    conn = sqlite3.connect(\"/home/ubuntu/data/crawl_datasets/\"+ '2018-03-21-harvest-WITH_cookies-WITH_js-NO_login'\n",
    "                           + \"/\" + 'crawl-data.sqlite')\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "df_visited_sites = pd.read_sql_query(\"SELECT * FROM site_visits\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print('Site visits table loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column with top level domains to the dataframe\n",
    "\n",
    "df_visited_sites['url_TLD'] = get_root_url(df_visited_sites, 'site_url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dataframes and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes with all visited sites and top level domain location and category\n",
    "\n",
    "df_merged = pd.merge(left=df_visited_sites, right=df_visited_cat, how='left', left_on='url_TLD', right_on='TopLevelDomainLookUp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>crawl_id</th>\n",
       "      <th>site_url</th>\n",
       "      <th>url_TLD</th>\n",
       "      <th>Country</th>\n",
       "      <th>Europe</th>\n",
       "      <th>PublicPrivate</th>\n",
       "      <th>SiteCategory</th>\n",
       "      <th>URLtype</th>\n",
       "      <th>TopLevelDomainLookUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1273</td>\n",
       "      <td>3</td>\n",
       "      <td>http://www.infolex.lv/portal/start.asp?act=pam...</td>\n",
       "      <td>infolex.lv</td>\n",
       "      <td>Latvia</td>\n",
       "      <td>EU</td>\n",
       "      <td>Private</td>\n",
       "      <td>LegalService</td>\n",
       "      <td>LawFirm</td>\n",
       "      <td>infolex.lv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>5139</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.stjornarradid.is/default.aspx?Page...</td>\n",
       "      <td>stjornarradid.is</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>EEA</td>\n",
       "      <td>Public</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stjornarradid.is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161</th>\n",
       "      <td>9162</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.elgiganten.dk</td>\n",
       "      <td>elgiganten.dk</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>EU</td>\n",
       "      <td>Private</td>\n",
       "      <td>Consumption</td>\n",
       "      <td>ShoppingUser</td>\n",
       "      <td>elgiganten.dk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>9452</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.hotnews.ro</td>\n",
       "      <td>hotnews.ro</td>\n",
       "      <td>Romania</td>\n",
       "      <td>EU</td>\n",
       "      <td>Private</td>\n",
       "      <td>News</td>\n",
       "      <td>PrivateMedia EU</td>\n",
       "      <td>hotnews.ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10284</th>\n",
       "      <td>10285</td>\n",
       "      <td>1</td>\n",
       "      <td>https://makler.md/ru/household-products/stitch...</td>\n",
       "      <td>makler.md</td>\n",
       "      <td>Moldova</td>\n",
       "      <td>NonEU</td>\n",
       "      <td>Private</td>\n",
       "      <td>Consumption</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>makler.md</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       visit_id  crawl_id                                           site_url  \\\n",
       "1272       1273         3  http://www.infolex.lv/portal/start.asp?act=pam...   \n",
       "5138       5139         1  https://www.stjornarradid.is/default.aspx?Page...   \n",
       "9161       9162         1                           http://www.elgiganten.dk   \n",
       "9451       9452         2                              http://www.hotnews.ro   \n",
       "10284     10285         1  https://makler.md/ru/household-products/stitch...   \n",
       "\n",
       "                url_TLD  Country Europe PublicPrivate  SiteCategory  \\\n",
       "1272         infolex.lv   Latvia     EU       Private  LegalService   \n",
       "5138   stjornarradid.is  Iceland    EEA        Public    Government   \n",
       "9161      elgiganten.dk  Denmark     EU       Private   Consumption   \n",
       "9451         hotnews.ro  Romania     EU       Private          News   \n",
       "10284         makler.md  Moldova  NonEU       Private   Consumption   \n",
       "\n",
       "               URLtype TopLevelDomainLookUp  \n",
       "1272           LawFirm           infolex.lv  \n",
       "5138               NaN     stjornarradid.is  \n",
       "9161      ShoppingUser        elgiganten.dk  \n",
       "9451   PrivateMedia EU           hotnews.ro  \n",
       "10284         Shopping            makler.md  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.sample(5).sort_values('visit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting as .csv\n",
    "\n",
    "df_merged.to_csv('/home/ubuntu/data/processed/' + 'visitedSitesCat.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain various metrics from response files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    • input: all enriched responses .csv files\n",
    "    • output: (i) TPs_per_site.json - number of unique TPs per site (ii) responses_total_combined.json - total number of a) all responses, b) all responses for EU/EEA, c) all responses for EU/EEA with FP-TP communication, and (iii) visited_sites_total_combined.json - total number of visited sites per harvest a) with responses, b) from EU/EEA, c) with FP-TP communication from EU/EEA\n",
    "    • script steps:\n",
    "        1. Import libraries\n",
    "        2. Iterate through all enriched responses files:\n",
    "            (a) Load a +response file as a dataframe\n",
    "            (b) Filter out all responses to non EU/EEA FP requests\n",
    "            (c) Filter out all FP-to-FP communication\n",
    "            (d) Calculate the number of unique TPs per site and append the results as a\n",
    "            JSON object to the corresponding list\n",
    "            (e) Calculate the number of responses: (i) all, (ii) EU/EEA only, and (iii) EU/EEA with FP-TP communication, and append the results as a JSON object to the corresponding list\n",
    "            (f) Calculate the number of visited sites: (i) with responses, (ii) with EU/EEA origin, and (iii) with with EU/EEA origin with FP-TP communication, and append the results as a JSON object to the corresponding list\n",
    "        3. Export each corresponding list as a separate .json file: (i) TPs_per_site, (ii) responses_total_combined, and (iii) TPs_total_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All possible outputs:\n",
    "    \n",
    "    1) Count how many responses per site (only TPs, no FP-FP communication)\n",
    "    2a) Count how many unique TPs per site (only TPs, no FP-FP communication)\n",
    "    2b) Occurence of each TP per site root domain\n",
    "    2c) Occurence of each TP per site visit\n",
    "    3a) Count how many unique TPs per FP category (only TPs, no FP-FP communication)\n",
    "    3b) Count how many unique TPs per FP category per sector (only TPs, no FP-FP communication)\n",
    "    3c) Count how many unique TPs per FP category per sector per URL type (only TPs, no FP-FP communication)\n",
    "    4) Occurance of each TP\n",
    "    5a) Number of unique TPs per country\n",
    "    5b) Number of responses per country\n",
    "    6) Total number of responses per crawl\n",
    "    7) Total number of unique TPs per crawl\n",
    "    8) Total number of sites per harvest - number of unique visit_id-s\n",
    "    9a) Total number of all RES for EU/EEA for FP-TP communication\n",
    "    9b) Total number of all RES for EU/EEA\n",
    "    9c) Total number of all RES\n",
    "    10 a) Total number of visited sites with FP-TP communication from EU/EEA\n",
    "    10 b) Total number of visited sites from EU/EEA\n",
    "    10 c) Total number of visited sites with a RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for loading CSVs to DFs\n",
    "def load_dataset(path, name):\n",
    "    df = pd.read_csv(path + name)\n",
    "    \n",
    "    print('Dataset ', name, ' loaded')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for exporting data in JSON\n",
    "def export_json(path, data, export_name):\n",
    "    with open(path + export_name + '.json',\"w\") as jsonFilehandle:\n",
    "        json_data = json.dumps(data)\n",
    "        jsonFilehandle.write(json_data)\n",
    "        jsonFilehandle.close()\n",
    "    \n",
    "    print('Exported ', export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for calling export in JSON with correct parameters\n",
    "def exporting(export_path, total_number_of_responses_per_site, total_number_of_TPs_per_site, \n",
    "              TP_occurence_per_site_TLD, TP_occurence_per_site_visit, total_number_of_TPs_cat, \n",
    "              total_number_of_TPs_cat_sector, total_occurence_of_TP, total_number_of_TPs_country, \n",
    "              total_number_of_res_country, total_number_of_res, total_number_of_TPs, total_number_of_TPs_per_cat_type_sector,\n",
    "              total_number_of_sites_per_harvest, total_number_of_total_res_COMB, total_number_visited_sites_COMB):\n",
    "    \n",
    "    # EXPORTING\n",
    "    # 1\n",
    "#    export_json(export_path, total_number_of_responses_per_site, 'responses_per_site')\n",
    "    # 2a)\n",
    "    export_json(export_path, total_number_of_TPs_per_site, 'TPs_per_site')\n",
    "    # 2b)\n",
    "#    export_json(export_path, TP_occurence_per_site_TLD, 'TP_occurence_per_site-TLD')\n",
    "    # 2c)\n",
    "#    export_json(export_path, TP_occurence_per_site_visit, 'TP_occurence_per_visit')\n",
    "    # 3a\n",
    "#    export_json(export_path, total_number_of_TPs_cat, 'TPs_per_cat')\n",
    "    # 3b\n",
    "#    export_json(export_path, total_number_of_TPs_cat_sector, 'TPs_per_cat_per_sector')\n",
    "    # 3c\n",
    "#    export_json(export_path, total_number_of_TPs_per_cat_type_sector, 'TPs_per_cat_per_sector_per_URLtype')\n",
    "    # 4\n",
    "#    export_json(export_path, total_occurence_of_TP, 'TP_occurance')\n",
    "    # 5a\n",
    "#    export_json(export_path, total_number_of_TPs_country, 'TPs_per_country')\n",
    "    # 5b\n",
    "#    export_json(export_path, total_number_of_res_country, 'responses_per_country')\n",
    "    # 6\n",
    "#    export_json(export_path, total_number_of_res, 'responses_total')\n",
    "    # 7\n",
    "#    export_json(export_path, total_number_of_TPs, 'TPs_total')\n",
    "    # 8 \n",
    "#    export_json(export_path, total_number_of_sites_per_harvest, 'unique_visit_ids_per_harvest')\n",
    "    # 9\n",
    "    export_json(export_path, total_number_of_total_res_COMB, 'responses_total_combined')\n",
    "    # 10\n",
    "    export_json(export_path, total_number_visited_sites_COMB, 'visited_sites_total_combined')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "f_path = '/home/ubuntu/data/processed/crawls/response_enriched/v.3/'\n",
    "export_path = '/home/ubuntu/data/processed/crawls/response_enriched/analysis_v.3/'\n",
    "\n",
    "# Set up regex pattern\n",
    "re_pattern = '\\d{4}\\W\\d{2}\\W\\d{2}'\n",
    "\n",
    "# Initialize empty lists\n",
    "total_number_of_responses_per_site = []\n",
    "total_number_of_TPs_per_site = []\n",
    "TP_occurence_per_site_TLD = []\n",
    "TP_occurence_per_site_visit = []\n",
    "total_number_of_TPs_cat = []\n",
    "total_number_of_TPs_cat_sector = []\n",
    "total_occurence_of_TP = []\n",
    "total_number_of_TPs_country = []\n",
    "total_number_of_res_country = []\n",
    "total_number_of_res = []\n",
    "total_number_of_TPs = []\n",
    "total_number_of_sites_per_harvest = []\n",
    "total_number_of_TPs_per_cat_type_sector = []\n",
    "total_number_of_total_res_COMB = []\n",
    "total_number_visited_sites_COMB = []\n",
    "\n",
    "# Initialize control variable\n",
    "i = 0\n",
    "\n",
    "# Get all file in the folder\n",
    "list_of_dataset_names = os.listdir(f_path)\n",
    "list_of_dataset_names\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for f_name in list_of_dataset_names:\n",
    "    if (f_name!='.ipynb_checkpoints'):\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        print(i, f_name)\n",
    "        \n",
    "        # Load dataset\n",
    "        df_res = load_dataset(f_path, f_name)\n",
    "        #print(df_res)\n",
    "        \n",
    "        # Get crawl date out of file name\n",
    "        crawl_date = re.findall(re_pattern, f_name)[0]\n",
    "        #print(\"Crawl date: \", crawl_date)\n",
    "        \n",
    "        # Reducing dataset column size\n",
    "        df_res_reduced = df_res[['visit_id', 'url', 'site_url', 'response_status', 'RD_url', 'RD_site_url', 'first_party',\n",
    "                                    'third_party', 'Country', 'Europe', 'PublicPrivate', 'SiteCategory','URLtype']]\n",
    "        #print(\"Columns reduced: \", df_res_reduced)\n",
    "        \n",
    "         # Filter out all non European sites\n",
    "        df_res_TP_EU = df_res_reduced[df_res_reduced['Europe'].isin(['EU', 'EEA'])]\n",
    "        #print(\"Only European sites: \", df_res_TP_EU)\n",
    "    \n",
    "        # Filter out all first-to-first party communication\n",
    "        df_res_filt = df_res_TP_EU.where(df_res_TP_EU['third_party']==True).dropna(subset=['third_party'])\n",
    "        #print(\"Only FP-to_TP comunication: \", df_res_filt)\n",
    "        \n",
    "        # Change visit_id column dtype to int\n",
    "        df_res_filt = df_res_filt.astype({'visit_id': 'int32'})\n",
    "        \n",
    "        # 1) Count how many responses per site (only TPs, no FP-FP communication)\n",
    "#        res_per_site = df_res_filt.groupby('RD_site_url').url.count().to_dict()\n",
    "#        json_obj = {'date': crawl_date, 'res_per_site': res_per_site}\n",
    "#        total_number_of_responses_per_site.append(json_obj)\n",
    "        #print(total_number_of_responses_per_site)\n",
    "        \n",
    "        # 2a) Count how many unique TPs per site (only TPs, no FP-FP communication)\n",
    "        occurence_TP_per_site = df_res_filt.groupby(['RD_site_url', 'RD_url']).size()\n",
    "        occurence_TP_per_site = occurence_TP_per_site.reset_index()\n",
    "        occurence_TP_per_site = occurence_TP_per_site.groupby('RD_site_url').size().to_dict()\n",
    "        json_obj = {'date': crawl_date, 'unique_TPs_per_site': occurence_TP_per_site}\n",
    "        total_number_of_TPs_per_site.append(json_obj)\n",
    "        #print(total_number_of_TPs_per_site)\n",
    "        \n",
    "        # 2b) Occurence of each TP per site TLD\n",
    "#        TP_occurence_per_site_TLD_data = {g:v['RD_url'].value_counts().to_dict() for g, v in df_res_filt.groupby('RD_site_url')}\n",
    "#        json_obj = {'date': crawl_date, 'TP_occurence_per_site_TLD': TP_occurence_per_site_TLD_data}\n",
    "#        TP_occurence_per_site_TLD.append(json_obj)\n",
    "        #print(TP_occurence_per_site_TLD)\n",
    "                   \n",
    "        # 2c) Occurence of each TP per site visit\n",
    "#        TP_occurence_per_visit = {g:v['RD_url'].value_counts().to_dict() for g, v in df_res_filt.groupby('visit_id')}\n",
    "#        json_obj = {'date': crawl_date, 'TP_occurence_per_visit': TP_occurence_per_visit}\n",
    "#        TP_occurence_per_site_visit.append(json_obj)\n",
    "        #print(TP_occurence_per_site_visit)\n",
    "       \n",
    "        # 3a) Count how many unique TPs per FP category (only TPs, no FP-FP communication)\n",
    "#        TPs_per_cat = df_res_filt.groupby('SiteCategory').url.count().to_dict()\n",
    "#        json_obj = {'date': crawl_date, 'TPs_per_cat': TPs_per_cat}\n",
    "#        total_number_of_TPs_cat.append(json_obj)\n",
    "        #print(total_number_of_TPs_cat)\n",
    "       \n",
    "        # 3b) Count how many unique TPs per FP category per sector (only TPs, no FP-FP communication)\n",
    "#        unique_TPs_per_cat_sector = {g:v['PublicPrivate'].value_counts().to_dict() for g, v in df_res_filt.groupby('SiteCategory')}\n",
    "#        json_obj = {'date': crawl_date, 'unique_TPs_per_cat_sector': unique_TPs_per_cat_sector}\n",
    "#        total_number_of_TPs_cat_sector.append(json_obj)\n",
    "        #print(total_number_of_TPs_cat_sector)\n",
    "        \n",
    "        # 3c) Count how many unique TPs per FP category per sector per URL type (only TPs, no FP-FP communication)\n",
    "#        df_grouped = df_res_filt.groupby(['SiteCategory','URLtype', 'PublicPrivate']).size()\n",
    "#        df_total_number_of_TPs_per_cat_type_sector = pd.DataFrame(df_grouped)\n",
    "#        df_total_number_of_TPs_per_cat_type_sector.rename(columns={0:'count'}, inplace=True)\n",
    "#        df_total_number_of_TPs_per_cat_type_sector = df_total_number_of_TPs_per_cat_type_sector.transpose()\n",
    "#        df_total_number_of_TPs_per_cat_type_sector['date'] = crawl_date\n",
    "#        json_total_number_of_TPs_per_cat_type_sector = df_total_number_of_TPs_per_cat_type_sector.to_json()\n",
    "#        json_parsed = json.loads(json_total_number_of_TPs_per_cat_type_sector)\n",
    "#        total_number_of_TPs_per_cat_type_sector.append(json_parsed)\n",
    "        #print(total_number_of_TPs_per_cat_type_sector)\n",
    "       \n",
    "        # 4) Occurance of each TP\n",
    "#        occurance_TP_total = df_res_filt.groupby('RD_url').size().to_dict()\n",
    "#        json_obj = {'date': crawl_date, 'occurance_TP_total': occurance_TP_total}\n",
    "#        total_occurence_of_TP.append(json_obj)\n",
    "        #print(total_occurence_of_TP)\n",
    "\n",
    "        # 5a) Number of unique TPs per country\n",
    "#        TPs_per_country = df_res_filt.groupby('Country').agg({'RD_url':'nunique'})\n",
    "#        unique_TPs_per_country = TPs_per_country.iloc[:,0].to_dict()\n",
    "#        json_obj = {'date': crawl_date, 'unique_TPs_per_country': unique_TPs_per_country}\n",
    "#        total_number_of_TPs_country.append(json_obj)\n",
    "        #print(total_number_of_TPs_country)\n",
    "\n",
    "        # 5b) Number of responses per country\n",
    "#        total_res_per_country = df_res_filt.groupby(['Country']).size().to_dict()\n",
    "#        json_obj = {'date': crawl_date, 'total_res_per_country': total_res_per_country}\n",
    "#        total_number_of_res_country.append(json_obj)\n",
    "        #print(total_number_of_res_country)\n",
    "\n",
    "        # 6) Total number of responses per crawl\n",
    "#        total_res = {'responses': len(df_res_filt)}\n",
    "#        json_obj = {'date': crawl_date, 'total_res': total_res}\n",
    "#        total_number_of_res.append(json_obj)\n",
    "        #print(total_number_of_res)\n",
    "\n",
    "        # 7) Total number of unique TPs per crawl\n",
    "#        total_TPs = {'TPs': len(df_res_filt['RD_url'].unique())}\n",
    "#        json_obj = {'date': crawl_date, 'total_TPs': total_TPs}\n",
    "#        total_number_of_TPs.append(json_obj)\n",
    "        #print(total_number_of_TPs)\n",
    "        \n",
    "        # 8) Total number of sites per harvest - number of unique visit_id-s\n",
    "#        number_of_sites_per_harvest = len(df_res_filt['visit_id'].unique())\n",
    "#        json_obj = {'date': crawl_date, 'total_sites': number_of_sites_per_harvest}\n",
    "#        total_number_of_sites_per_harvest.append(json_obj)\n",
    "        #print(total_number_of_sites_per_harvest)\n",
    "        \n",
    "        # 9a) Total number of all RES for EU/EEA for FP-TP communication\n",
    "        number_of_total_res_EU_FP_TP = len(df_res_filt)\n",
    "        # 9b) Total number of all RES for EU/EEA\n",
    "        number_of_total_res_EU = len(df_res_TP_EU)\n",
    "        # 9c) Total number of all RES\n",
    "        number_of_total_res = len(df_res)\n",
    "        json_obj = {'date': crawl_date, 'total_res_EU_FT_TP': number_of_total_res_EU_FP_TP, \n",
    "                    'total_res_EU': number_of_total_res_EU, 'total_res': number_of_total_res}\n",
    "        total_number_of_total_res_COMB.append(json_obj)\n",
    "        #print(total_number_of_total_res_COMB)\n",
    "        \n",
    "        # 10 a) Total number of visited sites with FP-TP communication from EU/EEA\n",
    "        number_of_visited_sites_EU_FpTp = len(df_res_filt['visit_id'].unique())\n",
    "        # 10 b) Total number of visited sites from EU/EEA\n",
    "        number_of_visited_sites_EU = len(df_res_TP_EU['visit_id'].unique())\n",
    "        # 10 c) Total number of visited sites with a RES\n",
    "        number_of_visited_sites = len(df_res['visit_id'].unique())\n",
    "        json_obj = {'date': crawl_date, 'visited_sites_EU_FP_TP': number_of_visited_sites_EU_FpTp, \n",
    "                    'visited_sites_EU': number_of_visited_sites_EU,'visited_sites': number_of_visited_sites}\n",
    "        total_number_visited_sites_COMB.append(json_obj)\n",
    "        #print(total_number_visited_sites_COMB)\n",
    "\n",
    "# Export        \n",
    "print('Export')\n",
    "exporting(export_path, total_number_of_responses_per_site, total_number_of_TPs_per_site, \n",
    "          TP_occurence_per_site_TLD, TP_occurence_per_site_visit, total_number_of_TPs_cat, \n",
    "          total_number_of_TPs_cat_sector, total_occurence_of_TP, total_number_of_TPs_country, \n",
    "          total_number_of_res_country, total_number_of_res, total_number_of_TPs, total_number_of_TPs_per_cat_type_sector,\n",
    "          total_number_of_sites_per_harvest, total_number_of_total_res_COMB, total_number_visited_sites_COMB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

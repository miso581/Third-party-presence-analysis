{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genererate presence of TPs over harvests\n",
    "Create a DF where all TPs from visited EU/EEA sites are as columns and all visited sites as index (their IDs). All harvest are interated over and all unique TP responses from EU/EEA visited sites are summed resulting in total counted appearance of each TP per visited site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    • input: (i) all enriched responses .csv files, and (ii) EU-UNIQUE-RES-TPs.csv - list of unique TPs\n",
    "    • output: EU_TP_total_occurence_count.csv - counted presence of each unique TP at every visited site over harvests\n",
    "    • script steps:\n",
    "        1. Import libraries\n",
    "        2. Load all unique TPs as a DF\n",
    "        3. Create an empty dataframe (df_distribution) with visited site IDs as index (1 – 12 778) and unique TPs as columns\n",
    "        4. Iterate through all enriched responses:\n",
    "            (a) Load response file as a DF\n",
    "            (b) Filter out all responses to non EU/EEA origin visited sites requests\n",
    "            (c) Filter out all FP-to-FP communication\n",
    "            (d) Group the response DF by visited site IDs (visit_ID) and TP root domains (RD_url), get the size, and create a new DF out of it\n",
    "            (e) Iterate through the grouped DF: (i) adds up 1 to the current value of the cell in the df_distribution at position [visit_ID, RD_url] every time the given TP appears in the given visited site responses\n",
    "        5. Export the df_distribution containing the occurrence of each unique TP at every visited site, during all harvests - EU_TP_total_occurence.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path and file name\n",
    "TPs_path = '/home/ubuntu/data/processed/TPs/TPs_merged/'\n",
    "TPs_name = 'EU-UNIQUE-RES-TPs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01mspmd5yalky8.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01net.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>030876vw.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0914.global.ssl.fastly.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0klxjejyxak3.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "0          01mspmd5yalky8.com\n",
       "1                   01net.com\n",
       "2                030876vw.com\n",
       "3  0914.global.ssl.fastly.net\n",
       "4            0klxjejyxak3.com"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all unique TPs\n",
    "df_TPs = pd.read_csv(TPs_path + TPs_name, header=None)\n",
    "df_TPs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define visit ids\n",
    "visit_ids = list(range(1, 12779))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01mspmd5yalky8.com</th>\n",
       "      <th>01net.com</th>\n",
       "      <th>030876vw.com</th>\n",
       "      <th>0914.global.ssl.fastly.net</th>\n",
       "      <th>0klxjejyxak3.com</th>\n",
       "      <th>1.98.201.35.bc.googleusercontent.com</th>\n",
       "      <th>100posto.hr</th>\n",
       "      <th>1053041200.rsc.cdn77.org</th>\n",
       "      <th>108.59.8.1</th>\n",
       "      <th>108.59.8.35</th>\n",
       "      <th>...</th>\n",
       "      <th>zrh50.cloudfront.net</th>\n",
       "      <th>zro56hd6szoy.com</th>\n",
       "      <th>ztat.net</th>\n",
       "      <th>ztkcdn.net</th>\n",
       "      <th>ztsrv.com</th>\n",
       "      <th>zumby.io</th>\n",
       "      <th>zuora.com</th>\n",
       "      <th>zuuvi.com</th>\n",
       "      <th>zvuki.ru</th>\n",
       "      <th>zxcvads.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0  01mspmd5yalky8.com  01net.com  030876vw.com  0914.global.ssl.fastly.net  \\\n",
       "1                   0          0             0                           0   \n",
       "2                   0          0             0                           0   \n",
       "3                   0          0             0                           0   \n",
       "4                   0          0             0                           0   \n",
       "5                   0          0             0                           0   \n",
       "\n",
       "0  0klxjejyxak3.com  1.98.201.35.bc.googleusercontent.com  100posto.hr  \\\n",
       "1                 0                                     0            0   \n",
       "2                 0                                     0            0   \n",
       "3                 0                                     0            0   \n",
       "4                 0                                     0            0   \n",
       "5                 0                                     0            0   \n",
       "\n",
       "0  1053041200.rsc.cdn77.org  108.59.8.1  108.59.8.35  ...  \\\n",
       "1                         0           0            0  ...   \n",
       "2                         0           0            0  ...   \n",
       "3                         0           0            0  ...   \n",
       "4                         0           0            0  ...   \n",
       "5                         0           0            0  ...   \n",
       "\n",
       "0  zrh50.cloudfront.net  zro56hd6szoy.com  ztat.net  ztkcdn.net  ztsrv.com  \\\n",
       "1                     0                 0         0           0          0   \n",
       "2                     0                 0         0           0          0   \n",
       "3                     0                 0         0           0          0   \n",
       "4                     0                 0         0           0          0   \n",
       "5                     0                 0         0           0          0   \n",
       "\n",
       "0  zumby.io  zuora.com  zuuvi.com  zvuki.ru  zxcvads.com  \n",
       "1         0          0          0         0            0  \n",
       "2         0          0          0         0            0  \n",
       "3         0          0          0         0            0  \n",
       "4         0          0          0         0            0  \n",
       "5         0          0          0         0            0  \n",
       "\n",
       "[5 rows x 6868 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DF with visited site IDs as indexes and all unique TPs as columns\n",
    "df_distribution = pd.DataFrame(index =visit_ids, columns = df_TPs[0])\n",
    "df_distribution = df_distribution.fillna(0)\n",
    "df_distribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed  1  -  ENR-RES-2019-05-29.csv\n",
      "Completed  2  -  ENR-RES-2019-04-05.csv\n",
      "Completed  3  -  ENR-RES-2019-02-21.csv\n",
      "Completed  4  -  ENR-RES-2020-05-12.csv\n",
      "Completed  5  -  ENR-RES-2018-04-17.csv\n",
      "Completed  6  -  ENR-RES-2018-06-12.csv\n",
      "Completed  7  -  ENR-RES-2019-06-14.csv\n",
      "Completed  8  -  ENR-RES-2019-04-12.csv\n",
      "Completed  9  -  ENR-RES-2018-04-09.csv\n",
      "Completed  10  -  ENR-RES-2018-11-07.csv\n",
      "Completed  11  -  ENR-RES-2018-09-21.csv\n",
      "Completed  12  -  ENR-RES-2019-11-13.csv\n",
      "Completed  13  -  ENR-RES-2018-08-03.csv\n",
      "Completed  14  -  ENR-RES-2020-06-19.csv\n",
      "Completed  15  -  ENR-RES-2019-01-30.csv\n",
      "Completed  16  -  ENR-RES-2018-02-14.csv\n",
      "Completed  17  -  ENR-RES-2019-07-12.csv\n",
      "Completed  18  -  ENR-RES-2020-02-25.csv\n",
      "Completed  19  -  ENR-RES-2018-07-17.csv\n",
      "Completed  20  -  ENR-RES-2018-10-09.csv\n",
      "Completed  21  -  ENR-RES-2018-03-21.csv\n",
      "Completed  22  -  ENR-RES-2020-06-02.csv\n",
      "Completed  23  -  ENR-RES-2018-06-01.csv\n",
      "Completed  24  -  ENR-RES-2020-01-13.csv\n",
      "Completed  25  -  ENR-RES-2018-10-31.csv\n",
      "Completed  26  -  ENR-RES-2019-11-05.csv\n",
      "Completed  27  -  ENR-RES-2018-06-18.csv\n",
      "Completed  28  -  ENR-RES-2020-03-24.csv\n",
      "Completed  29  -  ENR-RES-2019-05-01.csv\n",
      "Completed  30  -  ENR-RES-2018-12-10.csv\n",
      "Completed  31  -  ENR-RES-2018-03-29.csv\n",
      "Completed  32  -  ENR-RES-2019-05-27.csv\n",
      "Completed  33  -  ENR-RES-2020-02-07.csv\n",
      "Completed  34  -  ENR-RES-2018-06-07.csv\n",
      "Completed  35  -  ENR-RES-2018-02-07.csv\n",
      "Completed  36  -  ENR-RES-2018-07-06.csv\n",
      "Completed  37  -  ENR-RES-2018-05-19.csv\n",
      "Completed  38  -  ENR-RES-2019-12-22.csv\n",
      "Completed  39  -  ENR-RES-2018-05-29.csv\n",
      "Completed  40  -  ENR-RES-2019-03-12.csv\n",
      "Completed  41  -  ENR-RES-2019-09-02.csv\n",
      "Completed  42  -  ENR-RES-2018-11-19.csv\n",
      "Completed  43  -  ENR-RES-2020-04-07.csv\n",
      "Completed  44  -  ENR-RES-2019-04-24.csv\n",
      "Completed  45  -  ENR-RES-2018-05-05.csv\n",
      "Completed  46  -  ENR-RES-2019-06-28.csv\n",
      "Completed  47  -  ENR-RES-2018-08-31.csv\n",
      "Completed  48  -  ENR-RES-2018-05-25.csv\n",
      "Completed  49  -  ENR-RES-2020-03-10.csv\n",
      "Completed  50  -  ENR-RES-2019-10-29.csv\n",
      "Completed  51  -  ENR-RES-2018-09-06.csv\n",
      "Completed  52  -  ENR-RES-2019-08-05.csv\n",
      "Completed  53  -  ENR-RES-2018-09-11.csv\n",
      "Completed  54  -  ENR-RES-2019-11-28.csv\n",
      "Completed  55  -  ENR-RES-2019-09-20.csv\n",
      "Completed  56  -  ENR-RES-2018-02-09.csv\n",
      "Completed  57  -  ENR-RES-2019-10-03.csv\n",
      "Completed  58  -  ENR-RES-2019-03-27.csv\n",
      "Completed  59  -  ENR-RES-2019-10-16.csv\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Define folder with all harvest data\n",
    "harvests_path = '/home/ubuntu/data/processed/crawls/response_enriched/v.3/'\n",
    "\n",
    "i=0\n",
    "\n",
    "# Iterate through all file names in the folder\n",
    "for harvests_name in os.listdir(harvests_path):\n",
    "    if (harvests_name!='.ipynb_checkpoints'):\n",
    "        i += 1\n",
    "        # Load harvest\n",
    "        df_single_harvest = pd.read_csv(harvests_path + harvests_name)\n",
    "\n",
    "         # Filter out all non European sites\n",
    "        df_res_TP_EU = df_single_harvest[df_single_harvest['Europe'].isin(['EU', 'EEA'])]\n",
    "\n",
    "        # Filter out all first-to-first party communication\n",
    "        df_res_filt = df_res_TP_EU.where(df_res_TP_EU['third_party']==True).dropna(subset=['third_party'])\n",
    "        df_res_filt = df_res_filt[['visit_id', 'url', 'site_url', 'RD_url', 'RD_site_url']]\n",
    "\n",
    "        # Group DF by visit id and TP url\n",
    "        df_res_filt = df_res_filt.astype({'visit_id': 'int32'})\n",
    "        df_grouped = df_res_filt.groupby(['visit_id', 'RD_url']).size()\n",
    "\n",
    "        for index, value in df_grouped.items():\n",
    "            visit_id = index[0]\n",
    "            TP = index[1]\n",
    "            df_distribution.at[visit_id, TP] = int(df_distribution.at[visit_id, TP]) + 1\n",
    "\n",
    "        print('Completed ', i, ' - ', harvests_name)\n",
    "\n",
    "print('Completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df_distribution.to_csv('/home/ubuntu/data/processed/crawls/response_enriched/analysis_v.3/' + 'EU_TP_total_occurence_count.csv', index = True, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

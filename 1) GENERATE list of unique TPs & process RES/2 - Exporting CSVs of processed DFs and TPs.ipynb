{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process each harvest HTTP responses\n",
    "\n",
    "Load every harvest HTTP responses, find root domain of every response URL and originally requested site, and export as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    • input: .sqlite database file of each harvest\n",
    "    • output: enriched http_responses with a root domain of each visited site and response site, and columns indicating if response is FP-FP or FP-TP – CSV format\n",
    "    • script steps:\n",
    "        1. Import libraries\n",
    "        2. Iterate through extracted folders of all harvests:\n",
    "            (a) From an .sqlite database file load http_responses and site_visits tables as separate Dataframes (DFs)\n",
    "            (b) Merge responses and visited sites into a single DF based on visit_id column of both DFs\n",
    "            (c) In the merged DF find a Root domain (RD) of every originally requested site – FP (site_url column) and all response sites (url column) and assign root domains to new columns - RD_site_url, RD_url respectively\n",
    "            (d) Compare the RD_url and RD_site_url columns to find if the response RD matches the originally requested FP RD. If so, assign True to the new DF column – first_party, else assign False\n",
    "            (e) Export http_responses enriched with a root domain of each visited site and response site, and columns indicating if response is FP-FP or FP-TP – CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "import socket\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tld import get_tld, is_tld "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a database file and return HTTP resposes and visited sites tables as dataframes\n",
    "def load_tables(folder_name, file_name):\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"/home/ubuntu/data/crawl_datasets/\"+ folder_name + \"/\" + file_name)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    df_res = pd.read_sql_query(\"SELECT * FROM http_responses\", conn)\n",
    "    df_visited = pd.read_sql_query(\"SELECT * FROM site_visits\", conn)\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print('HTTP responses and site visits loaded')\n",
    "    return(df_res, df_visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take dataframe and column on which operations will be performed\n",
    "def get_root_url(df, column):\n",
    "\n",
    "    # Take the column and create a list out of it\n",
    "    urls = df[column].astype(str).tolist()\n",
    "    \n",
    "    # Initialize variables\n",
    "    root_url = []\n",
    "    re_IP_pattern = '(\\d{1,3}\\W\\d{1,3}\\W\\d{1,3}\\W\\d{1,3})'\n",
    "    \n",
    "    # For each site in the column list, first check if it is possible to retrieve a top level domain out of it \n",
    "    for site in urls:\n",
    "        root = get_tld(site, as_object=True, fail_silently=True)\n",
    "        \n",
    "        # If TLD can be obtained, find full domain and append it to the list\n",
    "        if root != None:\n",
    "            url_domain = get_tld(site, as_object=True).fld\n",
    "            root_url.append(url_domain)\n",
    "        \n",
    "        # If not, check if the site is an IP address\n",
    "        else:\n",
    "            IP_address = re.findall(re_IP_pattern, site)\n",
    "            \n",
    "            # If it is an IP address, try to do reversne DNS lookup to obtain a full top level domain\n",
    "            if IP_address:\n",
    "                try:\n",
    "                    domain_name = socket.gethostbyaddr(IP_address[0])[0]\n",
    "                    root_url.append(domain_name)\n",
    "                # If not possible, append IP address\n",
    "                except:\n",
    "                    root_url.append(IP_address[0])\n",
    "            # If it is not an IP address, append original URL\n",
    "            else:\n",
    "                root_url.append(site)\n",
    "\n",
    "    return(root_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-07-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 1\n",
      ".ipynb_checkpoints\n",
      "2018-07-06-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 2\n",
      "2018-02-07-harvest-WITH_cookies-NO_js-NO_login\n",
      "['crawl-data.sqlite', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 3\n",
      "2018-05-19-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['sokol-urls.txt', 'crawl-data.sqlite', 'sokol-harvest-links.py', 'sokol-readme.txt', 'sokol-extract-links.py', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 4\n",
      "2018-03-29-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 5\n",
      "2019-11-05-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 6\n",
      "2020-05-12-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 7\n",
      "2019-10-29-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 8\n",
      "2018-02-14-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 9\n",
      "2018-06-12-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 10\n",
      "2018-06-18-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 11\n",
      "2020-04-07-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 12\n",
      "2019-02-21-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 13\n",
      "2019-04-24-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 14\n",
      "2018-05-05-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sokol-harvest-links.py', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 15\n",
      "2018-05-29-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['sokol-urls.txt', 'crawl-data.sqlite', 'sokol-harvest-links.py', 'sokol-readme.txt', 'sokol-extract-links.py', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 16\n",
      "2019-08-05-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 17\n",
      "2018-08-03-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 18\n",
      "2018-07-17-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 19\n",
      "2018-03-21-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 20\n",
      "2018-09-06-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 21\n",
      "2020-06-19-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 22\n",
      "2020-01-13-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 23\n",
      "2020-06-02-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 24\n",
      "2018-04-09-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['sokol-urls.txt', 'crawl-data.sqlite', 'sokol-harvest-links.py', 'sokol-readme.txt', 'sokol-extract-links.py', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 25\n",
      "2018-10-09-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 26\n",
      "2019-04-05-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 27\n",
      "2018-11-19-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 28\n",
      "2018-06-01-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['sokol-urls.txt', 'crawl-data.sqlite', 'sokol-harvest-links.py', 'sokol-readme.txt', 'sokol-extract-links.py', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 29\n",
      "2019-06-28-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 30\n",
      "2018-02-09-harvest-WITH_cookies-NO_js-NO_login\n",
      "['crawl-data.sqlite', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 31\n",
      "2020-03-10-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 32\n",
      "2018-09-21-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 33\n",
      "2019-05-01-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 34\n",
      "2018-12-10-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 35\n",
      "2020-02-25-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 36\n",
      "2018-11-07-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 37\n",
      "2019-03-27-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 38\n",
      "2018-09-11-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 39\n",
      "2019-09-02-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 40\n",
      "2019-05-29-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 41\n",
      "2019-10-03-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 42\n",
      "2020-03-24-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 43\n",
      "2018-05-25-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['sokol-urls.txt', 'crawl-data.sqlite', 'sokol-harvest-links.py', 'sokol-readme.txt', 'sokol-extract-links.py', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 44\n",
      "2019-04-12-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', '.ipynb_checkpoints', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 45\n",
      "2018-08-31-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 46\n",
      "2019-09-20-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 47\n",
      "2018-10-31-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 48\n",
      "2019-07-12-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 49\n",
      "2019-11-28-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 50\n",
      "2019-03-12-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 51\n",
      "2019-01-30-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 52\n",
      "2019-11-13-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 53\n",
      "2019-06-14-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 54\n",
      "2020-02-07-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 55\n",
      "2019-10-16-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 56\n",
      "2019-12-22-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 57\n",
      "2018-04-17-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sokol-harvest-links.py', 'openwpm.log', 'sokol-links-to-visit-no-sublinks.txt', 'sokol-links-to-visit.txt']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 58\n",
      "2019-05-27-harvest-WITH_cookies-WITH_js-NO_login\n",
      "['crawl-data.sqlite', 'sources', 'screenshots', 'openwpm.log']\n",
      "HTTP responses and site visits loaded\n",
      "Finished merging\n",
      "Finished getting root URL\n",
      "Finished creating FP and TP columns\n",
      "Finished creating list of unique TPs\n",
      "Finished generating CSVs 59\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Get all folder names in the harvest data location\n",
    "list_of_crawl_folders = os.listdir('/home/ubuntu/data/crawl_datasets/')\n",
    "\n",
    "# Define a database file name\n",
    "file_name = 'crawl-data.sqlite'\n",
    "\n",
    "# Define variabels\n",
    "i = 0\n",
    "re_pattern= '\\d{4}\\D\\d{2}\\D\\d{2}'\n",
    "\n",
    "# Loop through all folder names\n",
    "for folder_name in list_of_crawl_folders:\n",
    "    print(folder_name)\n",
    "    \n",
    "    if (folder_name!='.ipynb_checkpoints'):\n",
    "        \n",
    "        # Get the crawl date from the folder name\n",
    "        crawl_date = re.match(re_pattern, folder_name).group()\n",
    "        print(os.listdir('/home/ubuntu/data/crawl_datasets/'+ folder_name))\n",
    "        \n",
    "        # Load tables to dataframes\n",
    "        df_res, df_visited = load_tables(folder_name, file_name)\n",
    "        \n",
    "        # Merge left df_res with df_visited on visit_id and crawl_id so that we have one dataframe \n",
    "            # containing all info needed\n",
    "        df_res_merged = df_res.merge(df_visited, left_on=['visit_id', 'crawl_id'], right_on=['visit_id','crawl_id'])[['crawl_id', 'visit_id', 'url', 'site_url', 'method', 'referrer', 'response_status', 'response_status_text', 'is_cached', 'headers', 'channel_id', 'time_stamp']]\n",
    "        print('Finished merging')\n",
    "        \n",
    "        # Find root domain of url accessed and originally visited site\n",
    "        root_domain_res = get_root_url(df_res_merged, 'url')\n",
    "        df_res_merged['RD_url'] = root_domain_res\n",
    "        root_domain_res = get_root_url(df_res_merged, 'site_url')\n",
    "        df_res_merged['RD_site_url'] = root_domain_res\n",
    "        print('Finished getting root URL')\n",
    "        \n",
    "        # Create a new column based on comparison of RD_url and RD_site_url to see which responses \n",
    "            # were FP and which TP\n",
    "        df_res_merged['first_party'] = np.where(df_res_merged[\"RD_url\"] == df_res_merged[\"RD_site_url\"], True, False)\n",
    "        df_res_merged['third_party'] = np.where(df_res_merged[\"RD_url\"] == df_res_merged[\"RD_site_url\"], False, True)\n",
    "        print('Finished creating FP and TP columns')\n",
    "        \n",
    "        # Generate .csv files for request and response merged dataframes and unique TPs\n",
    "        df_res_merged.to_csv (r'/home/ubuntu/data/processed/crawls/response/RES-'+ crawl_date +'.csv', index = False, header = True)\n",
    "        i += 1\n",
    "        print('Finished generating CSVs', i)\n",
    "        \n",
    "print('Completed')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
